{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHxFFnTgZf-3"
   },
   "source": [
    "# Step 1:\n",
    "## Initial setup - let's get some data!\n",
    "Before we start, let's first get some data. In Google Colabs you can execute shell commands by adding an exclamation like shown below. The **wget** command is a built-in utility that allows retrieving files from the web.\n",
    "\n",
    "**Note:** The wget command only works on the google colabs environment. To run this locally, download the data by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhXoFEiAHHmy"
   },
   "outputs": [],
   "source": [
    "! wget https://github.com/datamind-dotfit/python_for_data_science/raw/master/observations.xlsx https://github.com/datamind-dotfit/python_for_data_science/raw/master/sales.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KrZzK9pIdH7"
   },
   "source": [
    "### Verify data retrieval\n",
    "Let's verify that the data was actually retrieved and stored in the working directory. We can use the shell command 'ls' for this, it lists all the files in the current directory. We should see both *observations.xlsx* and *sales.xlsx* in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsjJo2a3Iahd"
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AdqmseoI0J_"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6rRxg1OZf-7"
   },
   "source": [
    "# Step 2:\n",
    "## Let's load the pandas library and our freshly retrieved data\n",
    "\n",
    "Load the pandas package and make sure you can access its functions through the name 'pd'. Remember in python we can import modules like so:\n",
    "\n",
    "```\n",
    "import module_name as some_shorthand\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOQa16HUZf-8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOWB_dc0Zf_E"
   },
   "source": [
    "Read in the two excel files that we downloaded in step 1.<br>\n",
    "http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQJKxllzZf_G"
   },
   "outputs": [],
   "source": [
    "\n",
    "sales = pd.read_excel('sales.xlsx')\n",
    "observations = pd.read_excel('observations.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQa-K1Vh3REi"
   },
   "source": [
    "# Step 3\n",
    "## Explore the data \n",
    "\n",
    "Let's start of by investigating some of the rows of our dataframe.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Questions:** <br>\n",
    "- Inspect the top of the sales dataframe. What's going on here?\n",
    "- Sample 20 random rows from the dataframe\n",
    "- Check out the seemingly empty columns. Which unique values do they contain? Is there anything other than NaN? <br>\n",
    "\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html <br>\n",
    "Note: unique() is only usable on a pandas Series, not on a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAtyQ5rGaZ2J"
   },
   "source": [
    "## Selecting with pandas' iloc\n",
    "Remember that you can use pandas' iloc functionality to access information by integer index:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "df.iloc[:, 3]\n",
    "```\n",
    "\n",
    "\n",
    "**Questions:**\n",
    "- Inspect the top of the observations dataframe. \n",
    "- What do you notice about the format of the data? How does it compare to the sales dataframe?\n",
    "- Find the name of the country and the year in the sixth row of the sales dataframe.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GvYn9P2-bcHq"
   },
   "source": [
    "## Filtering in pandas\n",
    "Filtering rows works by specifying the conditions that the rows should meet:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "df[df['column_one'] == 3]\n",
    "```\n",
    "\n",
    "**Questions:**\n",
    "- Find all rows in the observations dataframe where the value of 'pop' is greater than 80.\n",
    "- Find all rows in the sales dataframe concerning the Netherlands.\n",
    "- Now from those rows, select the bikes and year columns.\n",
    "- Add an extra filter: Find the row about the Netherlands in 1675."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZhOk2EbKfgh"
   },
   "source": [
    "## Joining data\n",
    "\n",
    "![alt text](https://i.stack.imgur.com/iJUMl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5PhcFK8mGUo"
   },
   "source": [
    "Now we know what the data looks like and what to expect from it, we can start thinking about merging the sales and observations dataframes. This will give us combined data on what happened in a country during a year. Before we can start joining, should any data transformations be performed? Remember that you can inspect the data frames with the .head() function. \n",
    "\n",
    "Using the str.title() function, which transforms any string into a version where only the first letter is capitalized, you can create uniform data among dataframes to join on. \n",
    "\n",
    "**Question:**\n",
    "- Make the relevant join data uniform among dataframes.\n",
    "\n",
    "Now that our country names are written in the exact same way, we can perform the join we have been speaking about. What do we join on, and why? \n",
    "\n",
    "**Questions:**\n",
    "- What happens if you join on only one column, such as the country or the year? \n",
    "- What happens if you join a dataframe to itself?\n",
    "\n",
    "Look up the way to join on multiple columns in the pandas documentation:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
    "\n",
    "- Think of when you would use which type of join. If you wanted to find all observations and, if possible, add the sales information to them, how would the code look?\n",
    "\n",
    "Try them all (create a df_inner, df_outer, df_left and df_right) and inspect the results to find out the effects of various joins. The following code will show you the shape of the dataframe in the format (rows, columns):\n",
    "\n",
    "```\n",
    "df.shape\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SbHc8I5ZNvs"
   },
   "source": [
    "## Missing values\n",
    "We now have a dataframe with all information in it. Upon closer inspection, you will see that the dataframe from the outer join has some missing values. Do you understand completely why this happens? \n",
    "\n",
    "In this section, we will inspect the missing values and deal with them in an appropriate manner. Let's clean up the dataframe from the outer join a bit\n",
    "\n",
    "**Questions**:\n",
    "- Delete all columns containing only NaN or duplicate data, making it easier to work with.\n",
    "- Find all rows that have null values.\n",
    "- Can we guess from which country the observations with the missing country value are?\n",
    "- If you had to fill in the missing values in the 'bikes', 'total_turnover' and 'pop' columns, how would you do this? Just think about it for now, later we will actually do it.\n",
    "\n",
    "Remember that the isnull() function helps you find rows containing null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tElMylz5oXql"
   },
   "source": [
    "## Aggregating data\n",
    "Aggregations are useful to get a quick look at derived statistics. At Datamind we often use these derived statistics to get a better picture of our data and also to fill in missing values. In this section we will get a clear picture on how to aggregate data while grouping.\n",
    "\n",
    "**Questions**:\n",
    "- Count the number of observations per country in the dataframe.\n",
    "- Calculate the average turnover per year\n",
    "- Create a dataframe containing the year, average turnover per year and average population per year\n",
    "- Calculate the maximum population per country.\n",
    "- Calculate the sum of the total turnover per year per country. Why is this not such a sensible statistic? Take note of what happens to the NaN observations.\n",
    "\n",
    "**Bonus**:\n",
    "- Calculate, for each row, the difference between the total turnover for this observation and the average turnover for that year and store this in a new dataframe containing all old columns plus the new one. For completeness, rename the new column to something appropriate.\n",
    "\n",
    "Hint: Create a new dataframe with the averages and join the new dataframe onto the old one. Then create a new column by subtracting one value from another:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "df['derived_column'] = df['original_column1'] * df['original_column2']\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PythonForDataScienceAssignments.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
