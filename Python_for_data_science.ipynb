{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python for data science.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit (conda)",
      "language": "python",
      "name": "python37464bitconda3a3aec03c3b94421ba984e37e5a0cb28"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESx5yhVKE5W6",
        "colab_type": "text"
      },
      "source": [
        "# <center>Datamind - Python for Data Science<center>\n",
        "Welcome to Python for Data Science! Today we'll deep dive into the world of Pandas, dataframes and dataframe operations. You may copy this notebook to your local Google Drive or computer to study the questions and answers later on. If you're not familiar with notebooks, please see https://jupyter-notebook.readthedocs.io/en/latest/notebook.html#notebook-documents for a quick introduction to Jupyter notebooks. These principles are directly applicable to Google Colabs notebooks.\n",
        "\n",
        "The notebook is divided into four sections, each step requires input from the previous step(s). If you have any questions, feel free to ask them in class or contact one of the trainers per e-mail!\n",
        "    \n",
        "**Some tips to get you started:**\n",
        "- Make new cells! You can make as many as you want, this way you can execute small code blocks and work iteratively.\n",
        "- Break larger problems down into small chunks (and work them out in individual code cells). Once you're convinced everything is in order, you can merge your code into one code cell.\n",
        "- Use comments to explain what you're doing, `#` allows you to write inline comments.\n",
        "- If you resort to Google or Stackoverflow for help, make sure you actually understand the solution that is provided. And rather than copying the code, make sure <u>*you*</u> write the code!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHxFFnTgZf-3"
      },
      "source": [
        "---\n",
        "\n",
        "# <center> Part one: getting data from the web. <center>\n",
        "## Getting data using `wget`\n",
        "Before we start, let's first get some data. In Google Colabs you can execute shell commands by adding an exclamation like shown below. The `wget` command is a built-in utility that allows retrieving files from the web. Executing a shell command means that this is no python code! Any commands that you find throughout this notebook that start with `!` are not usable in python code directly. For this you'll have to look into different solutions.\n",
        "\n",
        "**Note:** <br>The wget command only works on the Google Colabs environment or some Linux based systems. To run this locally, download the data by hand (by copying the links into a browsers) or change the command to whatever is applicable for your OS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eUf5kENE5W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget https://github.com/datamind-dotfit/python_for_data_science/raw/master/observations.xlsx https://github.com/datamind-dotfit/python_for_data_science/raw/master/sales.xlsx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8KrZzK9pIdH7"
      },
      "source": [
        "## Verify data retrieval\n",
        "Let's verify that the data was actually retrieved and stored in the working directory. We can use the shell command `ls` for this, this command lists all the files in the current directory. We should see both `observations.xlsx` and `sales.xlsx` in the result. As you may notice, there may be some other files in the directory, these files are there by default (or are located on your computer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vT45aQ6E5XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t6rRxg1OZf-7"
      },
      "source": [
        "\n",
        "# <br><center>Part two: Loading data</center>\n",
        "---\n",
        "## Import Pandas\n",
        "To load data we first have to import the Pandas module. After importing pandas, we can use many of its useful features to work with our data. In python we can import modules using the `import` statement. \n",
        "\n",
        "\n",
        "Load the pandas module and make sure you can access its functions through the name 'pd'. Remember in python we can import modules like so: <br>`import module_name as some_shorthand`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ943VbbE5XF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9KiIONzE5XK",
        "colab_type": "text"
      },
      "source": [
        "## Load in the data\n",
        "For this part we'll use the Pandas reader to load our files. Check what kind of file we downloaded in part one, and use the appropriate function to read both files in as data frames. See http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html for more information.\n",
        "\n",
        "#### Question:\n",
        "- What kind of files are we dealing with?\n",
        "- Read in the sales data as `sales` and the observations data as `observations`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrEw4-zUE5XK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What kind of files are we dealing with?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs7S-LjAE5XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the sales data as sales and the observations data as observations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YMFTuIrkZf_M"
      },
      "source": [
        "\n",
        "# <br><center>Part three: data exploration & cleaning </center>\n",
        "---\n",
        "## 3.1 - Explore the data \n",
        "Once we have the data loaded, it's time to explore! Let's start of by answering the following questions:\n",
        "\n",
        "#### Questions: \n",
        "- Inspect the top five and bottom five rows of the `sales` dataframe. What's going on here?\n",
        "- What's up with these column names, is this an error? Download the files by hand and see for yourself\n",
        "- We would like to sample 20 rows from the data frame at random, write the code for this.\n",
        "- Check out the seemingly empty columns. Which unique values do they contain? Is there anything other than NaN?\n",
        "- Create descriptive statistics of **both** data frames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSz-NbiqE5XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the top five and bottom five rows of the sales dataframe. What's going on here?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clCDtcIjE5XU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What's up with these column names, is this an error? Download the files by hand and see for yourself"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVWufqrCE5XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We would like to sample 20 rows from the data frame at random, write the code for this."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LnlcL0yE5Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check out the seemingly empty columns. Which unique values do they contain? Is there anything other than NaN?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEshhOeVE5Xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create descriptive statistics of both data frames."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TAtyQ5rGaZ2J"
      },
      "source": [
        "---\n",
        "## 3.2 - Selecting with pandas' iloc\n",
        "Remember that you can use Pandas' `iloc` functionality to access information by integer index `df.iloc[4]`. We may also select columns *directly* by index using `df.iloc[:, 3]`, or select columns *after* doing an `iloc` selection using `df.iloc[5]['ColumnName']`. \n",
        "\n",
        "#### Questions:\n",
        "- Inspect the top of the observations dataframe. What do you notice about the format of the data? How does it compare to the sales dataframe?\n",
        "- Find the name of the country and the year in the sixth row of the sales dataframe.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec93Yo4JE5Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inspect the top of the observations dataframe. What do you notice about the format of the data? How does it compare to the sales dataframe?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBUkahtPE5Xj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the name of the country and the year in the sixth row of the sales dataframe."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GvYn9P2-bcHq"
      },
      "source": [
        "---\n",
        "## 3.3 - Filtering in pandas\n",
        "\n",
        "### Pandas filtering, a look under the hood\n",
        "In this section you will practice filtering data in Pandas. Filtering in Pandas may look a bit daunting, but it's actually quite easy. Filtering is always done by following the same pattern and to understand how Pandas filtering works under the hood, we will first investigate the result of a filter/expression. After that you'll practice by applying these filters on the sales and observations data.\n",
        "\n",
        "Filtering is done by writing expressions that evaluate to `True` or `False`. There may be more than one expression, we can connect multiple expression by constructions such as AND and OR, you may have seen this before in mathematics or a course on logic. These expressions are often captured in a *truth table*. In pandas AND is indicated by `&` and or by `|`. \n",
        "\n",
        "The pattern to follow is:<br>\n",
        "`dataframe[dataframe['ColumnName'] == 'Value']`\n",
        "\n",
        "For multiple statements, we must put each expression between `(` and `)`.<br>\n",
        "`dataframe[(dataframe['ColumnName'] == 'Value') & (dataframe['SomeOtherColumn'] == 'SomeOtherValue')]`\n",
        "\n",
        "#### Question:\n",
        "- Write the expression `expression = sales['name_of_country'] == 'NETHERLANDS'`\n",
        "- Print out the expression, what do you see?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF51VG7gE5Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write the expression expression = sales['name_of_country'] == 'NETHERLANDS'\n",
        "# Print out the expression, what do you see?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TNgCL5okE5Xp"
      },
      "source": [
        "### Bringing it together\n",
        "So instead of selecting the rows by their index, we determine `True` or `False` for each row based on this expression. With this knowledge, try answer the questions below.\n",
        "\n",
        "**Questions:**\n",
        "- Find all rows in the observations dataframe where the value of 'pop' is greater than 80.\n",
        "- Find all rows in the sales dataframe concerning the Netherlands.\n",
        "- Now from those rows, select the bikes and year columns.\n",
        "- Add an extra filter: Find the row about the Netherlands in 1675.\n",
        "- Find all rows in the sales data frame where the country is Germany or France and the number of bikes are at least 49. In addition if the year is 1680, we also want to see that one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKfY697IE5Xp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find all rows in the observations dataframe where the value of 'pop' is greater than 80.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIx6fIjNE5Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find all rows in the sales dataframe concerning the Netherlands.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9AlqFUtE5Xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find all rows in the sales dataframe concerning the Netherlands.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QIKCf4_E5X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add an extra filter: Find the row about the Netherlands in 1675.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCQHU-dNE5X3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find all rows in the sales data frame where the country is Germany or France and the number of bikes are at least 49. In addition if the year is 1680, we also want to see that one.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BZhOk2EbKfgh"
      },
      "source": [
        "---\n",
        "## 3.4 - Joining data\n",
        "\n",
        "![alt text](https://i.stack.imgur.com/iJUMl.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E5PhcFK8mGUo"
      },
      "source": [
        "Now we know what the data looks like and what to expect from it, we can start thinking about merging the `sales` and `observations` dataframes. This will give us combined data on what happened in a country during a year. Before we can start joining, should any data transformations be performed? Remember that you can inspect the data frames with the `.head()` function. \n",
        "\n",
        "#### Question:\n",
        "- Investigate if the columns in both data frames are ready for joining, do we need to make any Transformations?\n",
        "- If your answer for the previous question is 'yes', then proceed to make adjustments so the column values are aligned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUHc6NdUE5X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Investigate if the columns in both data frames are ready for joining, do we need to make any Transformations?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTIhW00UE5X9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If your answer for the previous question is 'yes', then proceed to make adjustments so the column values are aligned."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SesIM10dE5X_"
      },
      "source": [
        "Now that our country names are written in the exact same way, we can perform the join we have been speaking about. What do we join on, and why? Look up the way to join on multiple columns in the pandas documentation:\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html\n",
        "\n",
        "#### Questions:\n",
        "- Think of when you would use which type of join. If you wanted to find all observations and, if possible, add the sales information to them, how would the code look?\n",
        "- What happens if you join on only one column, such as the country or the year? \n",
        "- What happens if you join a dataframe to itself?\n",
        "- Try them all (create a df_inner, df_outer, df_left and df_right) and inspect the results to find out the effects of various joins. The following code will show you the shape of the dataframe in the format (rows, columns): `df.shape`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9aWIhoFnAm7",
        "colab": {}
      },
      "source": [
        "# Think of when you would use which type of join. If you wanted to find all observations and, if possible, add the sales information to them, how would the code look?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqbNH6ChE5YC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What happens if you join on only one column, such as the country or the year?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4TbdbFiE5YE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What happens if you join a dataframe to itself?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx7uJJC1E5YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try them all (create a df_inner, df_outer, df_left and df_right) and inspect the results to find out the effects of various joins. \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6SbHc8I5ZNvs"
      },
      "source": [
        "---\n",
        "## 3.5 - Missing values\n",
        "We now have a dataframe with all information in it. Upon closer inspection, you will see that the dataframe from the **outer join** has some missing values. Do you understand completely why this happens? \n",
        "\n",
        "In this section, we will inspect the missing values and deal with them in an appropriate manner. Let's clean up the dataframe from the outer join a bit\n",
        "\n",
        "#### Questions:\n",
        "- Delete all columns containing only NaN or duplicate data, making it easier to work with.\n",
        "- Find all rows that have null values.\n",
        "- If you had to fill in the missing values in the 'bikes', 'total_turnover' and 'pop' columns, how would you do this? Just think about it for now, later we will actually do it.\n",
        "\n",
        "Remember that the `isnull()` function helps you find rows containing null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B12k5vt7E5YL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete all columns containing only NaN or duplicate data, making it easier to work with.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOCGz34nE5YP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find all rows that have null values.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG3otcibE5YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you had to fill in the missing values in the 'bikes', 'total_turnover' and 'pop' columns, how would you do this?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tElMylz5oXql"
      },
      "source": [
        "---\n",
        "## 3.6 - Aggregating data\n",
        "Aggregations are useful to get a quick look at derived statistics. At Datamind we often use these derived statistics to get a better picture of our data and also to fill in missing values. In this section we will get a clear picture on how to aggregate data while grouping.\n",
        "\n",
        "**Questions**:\n",
        "- Count the number of observations per country in the dataframe.\n",
        "- Calculate the average turnover per year\n",
        "- Create a dataframe containing the year, average turnover per year and average population per year\n",
        "- Calculate the maximum population per country.\n",
        "- Calculate the sum of the total turnover per year per country. Why is this not such a sensible statistic? Take note of what happens to the NaN observations.\n",
        "\n",
        "**Bonus**:\n",
        "- Calculate, for each row, the difference between the total turnover for this observation and the average turnover for that year and store this in a new dataframe containing all old columns plus the new one. For completeness, rename the new column to something appropriate.\n",
        "\n",
        "Hint: Create a new dataframe with the averages and join the new dataframe onto the old one. Then create a new column by subtracting one value from another:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "df['derived_column'] = df['original_column1'] * df['original_column2']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XJmAIxAroRhx",
        "colab": {}
      },
      "source": [
        "# Count the number of observations per country in the dataframe.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DLXmDN6Qo0D0",
        "colab": {}
      },
      "source": [
        "# Calculate the average turnover per year\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bQujCuFKsD-J",
        "colab": {}
      },
      "source": [
        "# Create a dataframe containing the year, average turnover per year and average population per year\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "COrNuzgz0AnM",
        "colab": {}
      },
      "source": [
        "# Calculate the maximum population per country.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ljXKneqWwVuE",
        "colab": {}
      },
      "source": [
        "# Calculate the sum of the total turnover per year per country. Why is this not such a sensible statistic? Take note of what happens to the NaN observations.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0663jwmLE5Yl",
        "colab_type": "text"
      },
      "source": [
        "Congratulations, you've made it to the end. With the techniques used in these exercises, you can do about 80% of the work with Pandas. You could further look into the Pandas `.apply()` function and plotting.\n",
        "\n",
        "# <br><br><center> Extra exercise </center>\n",
        "## Enrich our data frame using API information and store the resulting data frame using Pandas\n",
        "\n",
        "We can enrich our dataframe further by adding data from an API. Let's see if we can add country information to the data that we currently have. Let's use another public API to add the 2-letter ISOcode, longitude coordinates and latitude coordinates of each country that we have in our data set. This exercise is meant to take some time, feel free to experiment! This is where you learn the most.\n",
        "\n",
        "API: https://restcountries.eu/rest/v2/name\n",
        "\n",
        "This exercise requires you to do the following:\n",
        "- Collect all countries in your data set\n",
        "- Call the API for each country\n",
        "- Extract the information from the **JSON** request\n",
        "- Create a data frame from the API results\n",
        "- Join the data to your existing data frame\n",
        "- Inspect the results\n",
        "\n"
      ]
    }
  ]
}